{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cba6ca70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# OpenAI LLM\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Document Loading\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Environment vaiables\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8fce38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your API key from a .env file\n",
    "load_dotenv()\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75497576",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 118 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "# Loading PDF\n",
    "pdf_path = 'Resources/Resume - Tin Pham - Dec 2024.pdf'\n",
    "\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "069bfa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the text into management chunks\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500, # This ensures each chunk is within the token limit for GPT models\n",
    "    chunk_overlap = 50\n",
    ")\n",
    "\n",
    "chunks = splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5040341d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>617  Longhorn  Cavern  Rd.,  Leander,  TX  786...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>▪ \\n \\nCollaborated\\n \\nextensively\\n \\nwith\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>July  2019  –  February  2022             Goog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>processes\\n \\nwith\\n the  extended  Sales  tea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>accounts\\n \\nin\\n \\nSouth\\n \\nCentral\\n \\nfor\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chunk_id                                            content\n",
       "0         0  617  Longhorn  Cavern  Rd.,  Leander,  TX  786...\n",
       "1         1  ▪ \\n \\nCollaborated\\n \\nextensively\\n \\nwith\\n...\n",
       "2         2  July  2019  –  February  2022             Goog...\n",
       "3         3  processes\\n \\nwith\\n the  extended  Sales  tea...\n",
       "4         4  accounts\\n \\nin\\n \\nSouth\\n \\nCentral\\n \\nfor\\..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert chunks into a Pandas Dataframe\n",
    "df_chunks = pd.DataFrame([{\n",
    "    'chunk_id': i,\n",
    "    'content': chunk.page_content.strip()\n",
    "} for i, chunk in enumerate(chunks)])\n",
    "\n",
    "df_chunks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdd3d5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving DF to CSV\n",
    "df_chunks.to_csv('pdf_chunks.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbe51e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Chat Model\n",
    "llm = ChatOpenAI(openai_api_key = openai_key, temperature = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4057206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and Create a Vector Store for Retrieval\n",
    "# This gives us a searchable knowledge base made from your resume or report.\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# Create text list\n",
    "texts = [chunk.page_content for chunk in chunks]\n",
    "\n",
    "# Create embeddings and retriever\n",
    "embedding_model = OpenAIEmbeddings(openai_api_key = openai_key)\n",
    "vectorstore = FAISS.from_texts(texts, embedding_model)\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ed85441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Up Retrieval-Based QA Chain\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm = llm,\n",
    "    retriever = retriever,\n",
    "    chain_type = 'stuff'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "671a3b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': \"Can you give me a timeline of Tin's experience?\", 'result': \"Sure, here is a timeline of Tin Pham's experience based on the provided context:\\n\\n1. June 2012 – September 2012: Sales Consultant Extraordinaire at WP Engine in Austin, TX.\\n2. September 2012 – June 2013: Manager, Customer Experience at WP Engine in Austin, TX.\\n3. February 2022 – November 2024: Strategic Account Manager at DoiT International in Austin, TX.\\n\\nI hope this helps!\"}\n"
     ]
    }
   ],
   "source": [
    "# Ask a Question\n",
    "response = qa_chain.invoke(\"Can you give me a timeline of Tin's experience?\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
